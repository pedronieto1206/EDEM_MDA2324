# EDEM_MDA2324
Common Repository for 2023-2024 Data Master

<div align=center><img src="https://edem.eu/wp-content/uploads/2019/11/peces_edem.png" /></div>

El objetivo de este repositorio es servir de guía y de punto de comunicación entre alumnos y profesorado. Los alumnos deberán seguir las instrucciones que se indican en este documento para realizar las entregas de los trabajos y proyectos que se vayan solicitando a lo largo del curso.

## Instrucciones para la entrega de trabajos y proyectos

### 1. Usando vuestra cuenta de Github
### 2. Realizar un Fork de este repositorio

Para realizar un Fork de este repositorio, deberéis hacer click en el botón Fork que aparece en la parte superior derecha de la página. Esto creará una copia del repositorio en vuestra cuenta de Github.

### 3. Crear una carpeta con vuestro nombre y apellidos

Alumnos/PedroNieto/

### 4. Crear una carpeta por cada trabajo o proyecto

Alumnos/PedroNieto/Trabajo1/

### 5. Subir los archivos correspondientes a cada trabajo o proyecto

En cada commit, vuestro código será evaluado automáticamente por Github Actions. Si el código no pasa las pruebas, el commit será rechazado y no se podrá realizar la entrega. Si el código pasa las pruebas, el commit será aceptado y se podrá realizar la entrega.


### 6. Crear un Pull Request para que el profesor pueda revisar vuestros trabajos

Para crear un Pull Request, deberéis hacer click en el botón Pull Request que aparece en la parte superior derecha de la página. Esto creará una petición para que el profesor revise vuestros trabajos. En el título del Pull Request deberéis indicar vuestro nombre y apellidos para que sea revisado por el profesor correspondiente.

Para realizar la entrega de los trabajos y proyectos, deberéis crear una pull request en estado de Draft hasta que esté disponible para ser entregada. Una vez esté lista para ser entregada, deberéis cambiar el estado de la pull request a Ready for review. El profesor revisará vuestros trabajos y os indicará si es necesario realizar alguna corrección mediante conversaciones que tendréis que resolver para ser aceptada.

## Indice de Contenidos del Máster

Este máster está divido en tres grandes módulos, que permitirán al alumno adquirir los conocimientos en el ecosistema de Datos de una manera incremental desde lo más básico a lo menos básico ;-).

### Modulo 0 - Introducción 
Durante este bloque, los alumnos se centrarán en adquirir conocimientos básicos sobre datos, programación y despliegue de la tecnología necesaria para poder ejecutar el trabajo futuro. Descubrirán los controles de Linux, notebooks, aprenderán a trabajar en el lenguaje de programación Python junto con servicios de contenedores como Docker.

En resumen, este bloque les proporcionará una base sólida que les permitirá avanzar con naturalidad en su aprendizaje.

- Python

- Linux

- Git

- Containers (Docker)

- Notebooks

### Modulo 1 - Tratamiento del Dato
Durante este bloque, los alumnos se sumergirán en el perfil del Data Engineer: el profesional enfocado en el diseño, desarrollo y mantenimiento de los sistemas de procesamiento de datos dentro de un proyecto big data. Su función es dejar disponible el conjunto de datos validos con el que es necesario obtener, depurar y preparar los datos para su explotación.

Para ello, descubrirán el origen de los datos y su tipología, el manejo de grandes volúmenes de datos con SQL y NoSQL, creación de dashborads con su posterior creación en Tableau, el uso de tecnologías como Flask API’s, Kafka, Spark Streaming, Cloud, IAC Terraform y Localización, además de comprender el fujo de datos, su calidad y el gobierno de datos.

En resumen, este bloque les dará una base sólida para ocupar puestos de Data Engineer que se asegure de definir e implementar un flujo de datos desde su origen hasta su exploración de una forma controlada y automatizada.

- SQL
- NoSQL
- Tableau
- Flask API’s
- Kafka
- Spark Streaming
- Cloud
- IAC Terraform


### Modulo 2 - Análisis y aprendizaje automático

Durante este bloque, los alumnos se sumergirán en el perfil del Data Scientist: el profesional enfocado a entrenar modelos que extraen conocimiento sobre el problema a tratar a partir de los datos usando herramientas matemáticas y conocimientos del dominio de negocio.

Para ello, repasarán conocimientos de estadística y matemáticas dentro del entorno de programación con Python, usarán los diferentes métodos de clasificación, regresión, clustering y dimensionalidad dentro del machine learning y diferentes tipologías de redes neuronales como conectadas y convolucionales. Además, entenderán el estado del arte actual y su despliegue.

En resumen, este bloque les dará una base sólida para ocupar puestos de Data Scientist que se asegure de encontrar patrones y tendencias en los conjuntos de datos, crear algoritmos y modelos para predecir resultados y utilizar las técnicas de aprendizaje para mejorar la calidad de los datos.

